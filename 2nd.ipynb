{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Basic NLP with Python and NLTK - 2nd notebook\n",
    "Bruni Francesco (@brunifrancesco)\n",
    "\n",
    "This notebook @ https://github.com/brunifrancesco/nltk_base.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Previous notebook\n",
    "\n",
    "- Basic Python (functions, simple data structures, handling files)\n",
    "- Nltk foundations: tokenizing/cleaning/stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## This notebook\n",
    "\n",
    "- PMI computation\n",
    "- Writing result to CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pointwise Mutual Information\n",
    "\n",
    "<br />\n",
    "$${\\displaystyle PMI(X=x,Y=y)=\\log {\\frac {p(X=x,Y=y)}{p(X=x)p(Y=y)}}}$$\n",
    "<br />\n",
    "<br />\n",
    "where (*X and Y are independent*)\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "$${\\displaystyle p(X=x,Y=y) = p(X=x)*p(Y=y)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Proposed pipeline\n",
    "\n",
    "- Read from csv\n",
    "- Preprocess data (tokenize, lower, remove stopwords, punctuation)\n",
    "- Find frequency distribution for unigrams\n",
    "- Find frequency distribution for bigrams\n",
    "- Compute PMI via implemented function\n",
    "- Let NLTK sort bigrams by PMI metric\n",
    "- Write result to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import random\n",
    "from itertools import chain\n",
    "import math\n",
    "import csv\n",
    "import time\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    \"\"\"\n",
    "    Read data 'libe by line'\"\"\"\n",
    "    with open('data.csv', 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            yield row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    \"\"\"\n",
    "    Preprocess data, filtering out stopwords, punctuation and lowering \n",
    "    all splitted tokens\n",
    "    \n",
    "    :param data: the string data to be processed\n",
    "    \"\"\"\n",
    "    italian_stopwords = stopwords.words('italian')\n",
    "    splitted_chunks = data.split()\n",
    "    lowered_chunks = (item.lower() for item in splitted_chunks)\n",
    "    chunks_without_punctuation = (chunk for chunk in lowered_chunks if chunk not in string.punctuation)\n",
    "    chunks_without_stopwords = (chunk for chunk in chunks_without_punctuation if chunk not in italian_stopwords)\n",
    "    return list(chunks_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "FREQUENCY_TRESHOLD = 2\n",
    "\n",
    "def find_bigrams(splitted_chunks):\n",
    "    \"\"\"\n",
    "    Find bigrams and filter them by frequency threshold\n",
    "    \n",
    "    :param splitted_chunks: a list of chunks\n",
    "    \"\"\"\n",
    "    bigrams = nltk.collocations.BigramCollocationFinder.from_words(splitted_chunks)\n",
    "    bigrams.apply_freq_filter(FREQUENCY_TRESHOLD)\n",
    "    return {bigram: freq for bigram, freq in bigrams.ngram_fd.items()}\n",
    "\n",
    "def find_unigrams(splitted_chunks):\n",
    "    \"\"\"\n",
    "    Find unigrams and filter them by frequency threshold\n",
    "    \n",
    "    :param splitted_chunks: a list of chunks\n",
    "    \"\"\"\n",
    "    unigrams = nltk.FreqDist(splitted_chunks)\n",
    "    return {unigram: freq for unigram, freq in unigrams.items() if freq > FREQUENCY_TRESHOLD - 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def pmi(word1, word2, unigram_freq, bigram_freq):\n",
    "    \"\"\"\n",
    "    Find PMI measure\n",
    "    \n",
    "    :param word1: the first word\n",
    "    :param word2: the second word\n",
    "    :param unigram_freq: the unigram frequency container\n",
    "    :param bigram_freq: the bigram frequency container\n",
    "    \n",
    "    \"\"\"\n",
    "    prob_word1 = unigram_freq[word1] / sum(unigram_freq.values())\n",
    "    prob_word2 = unigram_freq[word2] / sum(unigram_freq.values())\n",
    "    prob_word1_word2 = bigram_freq[(word1, word2)] / sum(bigram_freq.values())\n",
    "    a = prob_word1_word2/prob_word1*prob_word2\n",
    "    return round(math.log(a,2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def find_best_bigrams(chunks):\n",
    "    \"\"\"\n",
    "    Find best bigrams via nltk bigram metric association\n",
    "    \n",
    "    :param splitted_chunks: a list of chunks\n",
    "    \"\"\"\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    finder = nltk.collocations.BigramCollocationFinder.from_words(chunks)\n",
    "    finder.apply_freq_filter(FREQUENCY_TRESHOLD)\n",
    "    return finder.nbest(bigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def write_data(result):\n",
    "    \"\"\"\n",
    "    Write result to CSV file\n",
    "    \n",
    "    :param result: the list to be written to csv file\n",
    "    \"\"\"\n",
    "    with open(\"result.csv\", \"a\") as output:\n",
    "        writer = csv.writer(output, delimiter='*')\n",
    "        for row in result:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing row: (FI),ricorda che nel...\n",
      "*****************************************************************************************************\n",
      "\"Found (via pmi computation): [('reato tortura', -0.42)]\"\n",
      "**********************************************************************\n",
      "\"Found (via nltk pmi metric association): [('reato', 'tortura')]\"\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Processing row: rileva che l'estensi...\n",
      "*****************************************************************************************************\n",
      "\"Found (via pmi computation): [('reato tortura', 0.0)]\"\n",
      "**********************************************************************\n",
      "\"Found (via nltk pmi metric association): [('reato', 'tortura')]\"\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Processing row: Onorevole Giachetti,...\n",
      "*****************************************************************************************************\n",
      "'Found (via pmi computation): [(\"procedere all\\'esame\", 0.0)]'\n",
      "**********************************************************************\n",
      "'Found (via nltk pmi metric association): [(\\'procedere\\', \"all\\'esame\")]'\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Processing row: Signor Presidente, o...\n",
      "*****************************************************************************************************\n",
      "(\"Found (via pmi computation): [('vengono tutelate', -3.5), ('sistema \"\n",
      " \"finanziario', -5.96), ('testo esame,', -3.77), ('tema generale', -4.82), \"\n",
      " '(\"all\\'interno sistema\", -3.36), (\\'soggetti interessati\\', -4.09), '\n",
      " \"('discussione provvedimento', -3.5), ('sistema imprenditoriale', -6.55), \"\n",
      " \"('che, pur', -5.31), ('imprese interessate', -6.79), ('strumento \"\n",
      " \"decreto-legge', -4.41), ('stato detto,', -5.09), ('imprese fornitrici', \"\n",
      " \"-6.79), ('v commissione', -4.09), ('mettere repentaglio', -4.24), ('gi√† \"\n",
      " \"stato', -4.09)]\")\n",
      "**********************************************************************\n",
      "(\"Found (via nltk pmi metric association): [('soggetti', 'interessati'), ('v', \"\n",
      " \"'commissione'), ('vengono', 'tutelate'), ('mettere', 'repentaglio'), \"\n",
      " \"('tema', 'generale'), ('stato', 'detto,'), ('strumento', 'decreto-legge'), \"\n",
      " \"('testo', 'esame,'), ('che,', 'pur'), ('sistema', 'imprenditoriale')]\")\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Processing row: Signor Presidente, i...\n",
      "*****************************************************************************************************\n",
      "(\"Found (via pmi computation): [('crisi grandi', -5.58), ('fondi stanziati', \"\n",
      " \"-6.39), ('ampliamo platea', -4.0), ('far fronte', -4.0), ('imprese \"\n",
      " 'trasporto\\', -7.17), (\\'n. 662\\', -5.91), (\"l\\'articolo aggiuntivo\", -4.58), '\n",
      " \"('salvaguardare bilancio', -2.78), ('espresso parere', -3.58), ('tali \"\n",
      " \"questioni', -4.58), ('tetto spesa,', -5.58), ('commissione bilancio,', \"\n",
      " \"-4.07), ('fondo garanzia,', -4.58), ('trasporto collegate', -4.58), \"\n",
      " \"('decreto-legge n.', -4.85), ('ci√≤ significa', -5.17), ('momento ampliamo', \"\n",
      " \"-5.17), ('bilancio stato', -6.39), ('n. 347', -5.91), ('legge n.', -3.85), \"\n",
      " \"('commissione bilancio', -4.58), ('decreto-legge esame', -5.17), ('platea \"\n",
      " \"soggetti', -5.17)]\")\n",
      "**********************************************************************\n",
      "(\"Found (via nltk pmi metric association): [('fondo', 'garanzia,'), \"\n",
      " '(\"l\\'articolo\", \\'aggiuntivo\\'), (\\'tali\\', \\'questioni\\'), (\\'trasporto\\', '\n",
      " \"'collegate'), ('ampliamo', 'platea'), ('ci√≤', 'significa'), ('far', \"\n",
      " \"'fronte'), ('momento', 'ampliamo'), ('platea', 'soggetti'), ('crisi', \"\n",
      " \"'grandi')]\")\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Processing row: Signor Presidente, i...\n",
      "*****************************************************************************************************\n",
      "(\"Found (via pmi computation): [('proposte emendative', -3.17), ('verso \"\n",
      " \"marchio', -2.58), ('alcune proposte', -2.58), ('imprese agricole', -4.58), \"\n",
      " \"('maggiori certezze', -3.17), ('consumatori verso', -2.58)]\")\n",
      "**********************************************************************\n",
      "(\"Found (via nltk pmi metric association): [('consumatori', 'verso'), \"\n",
      " \"('verso', 'marchio'), ('maggiori', 'certezze'), ('proposte', 'emendative'), \"\n",
      " \"('alcune', 'proposte'), ('imprese', 'agricole')]\")\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Processing row: Signor Presidente, l...\n",
      "*****************************************************************************************************\n",
      "\"Found (via pmi computation): [('emendamenti marcora', 1.32)]\"\n",
      "**********************************************************************\n",
      "\"Found (via nltk pmi metric association): [('emendamenti', 'marcora')]\"\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Processing row: Sta bene.Prendo atto...\n",
      "*****************************************************************************************************\n",
      "(\"Found (via pmi computation): [('marcora 1.1', -2.32), ('1.1 gambini', \"\n",
      " \"-1.74), ('emendamenti marcora', -2.32), ('identici emendamenti', -2.32), \"\n",
      " \"('mediante procedimento', -2.32)]\")\n",
      "**********************************************************************\n",
      "(\"Found (via nltk pmi metric association): [('emendamenti', 'marcora'), \"\n",
      " \"('identici', 'emendamenti'), ('marcora', '1.1'), ('mediante', \"\n",
      " \"'procedimento'), ('1.1', 'gambini')]\")\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Processing row: Signor Presidente, i...\n",
      "*****************************************************************************************************\n",
      "(\"Found (via pmi computation): [('gi√† esistenti', -1.0), ('sezioni \"\n",
      " \"specializzate,', -2.32)]\")\n",
      "**********************************************************************\n",
      "(\"Found (via nltk pmi metric association): [('gi√†', 'esistenti'), ('sezioni', \"\n",
      " \"'specializzate,')]\")\n",
      "*****************************************************************************************************\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pprint\n",
    "\n",
    "# get the first five rows\n",
    "top_five_rows = itertools.islice(read_data(), 1, 30)\n",
    "\n",
    "# iterate over the rows and apply the pipeline\n",
    "for row in top_five_rows:\n",
    "    \n",
    "    splitted_chunks = preprocess(row[3])\n",
    "    bigrams = find_bigrams(splitted_chunks)\n",
    "    unigrams = find_unigrams(splitted_chunks)\n",
    "    data = [\n",
    "        (\" \".join(key), pmi(key[0], key[1],unigrams, bigrams )) for key in bigrams.keys()\n",
    "    ]\n",
    "    nltk_data = find_best_bigrams(splitted_chunks)\n",
    "    \n",
    "    # if somethin 'valuable' has been found, let's print it out\n",
    "    if data:\n",
    "        print()\n",
    "        print()\n",
    "        print(\"Processing row: %s...\" %row[3][:20])\n",
    "        print(\"*****************************************************************************************************\")\n",
    "        pprint.pprint(\"Found (via pmi computation): %s\" %data)\n",
    "        print(\"**********************************************************************\")\n",
    "        pprint.pprint(\"Found (via nltk pmi metric association): %s\" %nltk_data)\n",
    "        print(\"*****************************************************************************************************\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"-----------------------------------------------------------------------------------------------------\")\n",
    "        write_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
